theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs with relative abundance higher than 0.01% mapped") +
theme(axis.title.x=element_blank()) +
facet_wrap(~Location, ncol = 8) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10))
FigureS1b <- ggplot(data=top_AD, aes(x=database, y=fraction, fill=Identity)) +
theme_bw() +
geom_bar(color="black",stat="identity", width=0.8) +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs with relative abundance higher than 0.01% mapped") +
theme(axis.title.x=element_blank()) +
facet_wrap(~Location, ncol = 8) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10))
ggsave(filename="output/Figure1b.pdf", plot=Figure1b, width=10, height=5, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/Figure1b.pdf", plot=Figure1b, width=10, height=5, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/FigureS1a.pdf", plot=FigureS1a, width=16, height=length(unique(top_AS$Location))/8*2+2, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/FigureS1b.pdf", plot=FigureS1b, width=16, height=length(unique(top_AD$Location))/8*2+2, useDingbats=FALSE, limitsize=FALSE)
View(coverage_01pct)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Define function to read mapping results
read_amp_mappings <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,3) %>%
rename(ASV = V1, !!gsub(".*vs_(.+).b6", "\\1", paste(input)):=V3) %>%
arrange(readr::parse_number(ASV))
}
# Import read mappings for all reference databases
a <- read_amp_mappings("data/ASVs_vs_FL-ASVs.b6")
b <- read_amp_mappings("data/ASVs_vs_FL-ASVs+FL-OTUs.b6")
c <- read_amp_mappings("data/ASVs_vs_MiDAS_2.1.b6")
d <- read_amp_mappings("data/ASVs_vs_gg_16s_13.5.b6")
e <- read_amp_mappings("data/ASVs_vs_RDP_all_11.5.b6")
f <- read_amp_mappings("data/ASVs_vs_SILVA_138_SSURef_NR99.b6")
g <- read_amp_mappings("data/ASVs_vs_SILVA_138_SSURef.b6")
h <- read_amp_mappings("data/ASVs_vs_GTDB_r89.b6")
# Create a merged dataframe with all read mappings
V13ASV_vs_all <- list(a,b,c,d,e,f,g,h) %>%
reduce(left_join, by = "ASV")
# Read ASV-table
ASVtable <- read.delim("data/V13ASVtab.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
rename(ASV=1) %>%
arrange(readr::parse_number(ASV))
# Merge ASV table and read mapping data based on ASVs
df <- left_join(ASVtable, V13ASV_vs_all, by="ASV")
# Determine the relative abundance of each ASV in each sample
ranked <- df %>%
gather(2:7, key="SeqID", value="counts") %>%
group_by(SeqID) %>%
arrange(desc(counts)) %>%
mutate(rank = row_number(), relative_abundance = counts/sum(counts)*100) %>%
ungroup() %>%
gather(2:9, key="database", value="Identity") %>%
mutate(database = factor(database, levels = c("FL-ASVs","FL-ASVs+FL-OTUs", "gg_16s_13.5", "GTDB_r89","MiDAS_2.1","RDP_all_11.5", "SILVA_138_SSURef_NR99", "SILVA_138_SSURef")))
# Load sample metadata
Sample_metadata <- read.delim("data/Sample_metadata.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE)
# Merge the ASV relative abundance data with the metadata
ranked_w_metadata <- left_join(ranked, Sample_metadata, by="SeqID")
coverage <- ranked_w_metadata %>%
filter(relative_abundance >= 0.01 & database=="FL-ASVs") %>%
group_by(SeqID,database) %>%
summarize("coverage"=sum(relative_abundance)) %>%
group_by(database) %>%
summarise(mean=mean(coverage), sd=sd(coverage), n=n())
d1 <- ranked_w_metadata %>%
filter(relative_abundance > 0.01 & counts>0) %>%
group_by(database) %>%
summarize("100%"=sum(Identity==100.0)/n()*100,
">98.7%"=(sum(Identity>=98.7)-sum(Identity==100.0))/n()*100,
">94.5%"=(sum(Identity>=94.5)-sum(Identity>=98.7))/n()*100,
"detected_amplicons"=n(),
"Relative_abundance"=paste("Dutch WWTPs\n","Relative abundance > 0.01%\n","Coverage: ",sprintf("%.1f", coverage$mean),"% ± ",sprintf("%.1f",coverage$sd),"%, n=",coverage$n, sep="")) %>%
gather(2:4, key="temp_Identity", value = "fraction") %>%
mutate(Identity=factor(temp_Identity, levels=c(">94.5%",">98.7%","100%")))
d2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.01) %>%
group_by(WWTP, database) %>%
summarize("100%"=sum(Identity==100.0)/n()*100,
">98.7%"=(sum(Identity>=98.7)-sum(Identity==100.0))/n()*100,
">94.5%"=(sum(Identity>=94.5)-sum(Identity>=98.7))/n()*100,
"detected_amplicons"=n()) %>%
gather(3:5, key="temp_Identity", value = "fraction") %>%
mutate(Identity=factor(temp_Identity, levels=c(">94.5%",">98.7%","100%")))
Figure1c <- ggplot(data=d1, aes(x=database, y=fraction, fill=Identity)) +
theme_bw() +
geom_bar(color="black",stat="identity", width=0.8) +
theme(axis.text.x = element_text(angle = 45, vjust=1, hjust=1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs mapped") +
theme(axis.title.x=element_blank()) +
facet_grid(.~Relative_abundance) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10), expand=c(0,2))
FigureS2a<- ggplot(data=d2, aes(x=database, y=fraction, fill=Identity)) +
theme_bw() +
geom_bar(color="black",stat="identity", width=0.8) +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs with relative abundance\n higher than 0.01% mapped") +
theme(axis.title.x=element_blank()) +
facet_wrap(~WWTP, ncol = 6) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10), expand=c(0,2))
ggsave(filename="output/Figure1c.pdf", plot=Figure1c, width=4.5, height=3.5, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/FigureS2a.pdf", plot=FigureS2a, width=12, height=3.5, useDingbats=FALSE, limitsize=FALSE)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Define function to read mapping results
read_amp_mappings <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,3) %>%
rename(ASV = V1, !!gsub(".*vs_(.+).b6", "\\1", paste(input)):=V3) %>%
arrange(readr::parse_number(ASV))
}
# Import read mappings for all reference databases
a <- read_amp_mappings("data/ASVs_vs_FL-ASVs.b6")
b <- read_amp_mappings("data/ASVs_vs_FL-ASVs+FL-OTUs.b6")
c <- read_amp_mappings("data/ASVs_vs_MiDAS_2.1.b6")
d <- read_amp_mappings("data/ASVs_vs_gg_16s_13.5.b6")
e <- read_amp_mappings("data/ASVs_vs_RDP_all_11.5.b6")
f <- read_amp_mappings("data/ASVs_vs_SILVA_138_SSURef_NN99.b6")
# Define function to read mapping results
read_amp_mappings <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,3) %>%
rename(ASV = V1, !!gsub(".*vs_(.+).b6", "\\1", paste(input)):=V3) %>%
arrange(readr::parse_number(ASV))
}
# Import read mappings for all reference databases
a <- read_amp_mappings("data/ASVs_vs_FL-ASVs.b6")
b <- read_amp_mappings("data/ASVs_vs_FL-ASVs+FL-OTUs.b6")
c <- read_amp_mappings("data/ASVs_vs_MiDAS_2.1.b6")
d <- read_amp_mappings("data/ASVs_vs_gg_16s_13.5.b6")
e <- read_amp_mappings("data/ASVs_vs_RDP_all_11.5.b6")
f <- read_amp_mappings("data/ASVs_vs_SILVA_138_SSURef_NR99.b6")
g <- read_amp_mappings("data/ASVs_vs_SILVA_138_SSURef.b6")
h <- read_amp_mappings("data/ASVs_vs_GTDB_r89.b6")
# Create a merged dataframe with all read mappings
ASV_vs_all <- list(a,b,c,d,e,f,g,h) %>%
reduce(left_join, by = "ASV")
# Read ASV-table
ASVtable <- read.delim("data/V35ASVtab.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
rename(ASV=1) %>%
arrange(readr::parse_number(ASV))
# Merge ASV table and read mapping data based on ASVs
df <- left_join(ASVtable, ASV_vs_all, by="ASV")
# Determine the relative abundance of each ASV in each sample
ranked <- df %>%
gather(2:40, key="SeqID", value="counts") %>%
group_by(SeqID) %>%
arrange(desc(counts)) %>%
mutate(rank = row_number(), relative_abundance = counts/sum(counts)*100) %>%
ungroup() %>%
gather(2:9, key="database", value="Identity") %>%
mutate(database = factor(database, levels = c("FL-ASVs","FL-ASVs+FL-OTUs", "gg_16s_13.5", "GTDB_r89","MiDAS_2.1","RDP_all_11.5", "SILVA_138_SSURef_NR99", "SILVA_138_SSURef")))
# Load sample metadata
Sample_metadata <- read.delim("data/SraRunTable.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE)
# Merge the ASV relative abundance data with the metadata
ranked_w_metadata <- left_join(ranked, Sample_metadata, by="SeqID") %>%
filter(WWTP!="RAS")
coverage <- ranked_w_metadata %>%
filter(relative_abundance >= 0.01 & database=="FL-ASVs") %>%
group_by(SeqID,database) %>%
summarize("coverage"=sum(relative_abundance)) %>%
group_by(database) %>%
summarise(mean=mean(coverage), sd=sd(coverage), n=n())
d1 <- ranked_w_metadata %>%
filter(relative_abundance > 0.01 & counts>0) %>%
group_by(database) %>%
summarize("100%"=sum(Identity==100.0)/n()*100,
">98.7%"=(sum(Identity>=98.7)-sum(Identity==100.0))/n()*100,
">94.5%"=(sum(Identity>=94.5)-sum(Identity>=98.7))/n()*100,
"detected_amplicons"=n(),
"Relative_abundance"=paste("Canadian WWTPs\n","Relative abundance > 0.01%\n","Coverage: ",sprintf("%.1f", coverage$mean),"% ± ",sprintf("%.1f",coverage$sd),"%, n=",coverage$n, sep="")) %>%
gather(2:4, key="temp_Identity", value = "fraction") %>%
mutate(Identity=factor(temp_Identity, levels=c(">94.5%",">98.7%","100%")))
d2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.01) %>%
group_by(WWTP, database) %>%
summarize("100%"=sum(Identity==100.0)/n()*100,
">98.7%"=(sum(Identity>=98.7)-sum(Identity==100.0))/n()*100,
">94.5%"=(sum(Identity>=94.5)-sum(Identity>=98.7))/n()*100,
"detected_amplicons"=n()) %>%
gather(3:5, key="temp_Identity", value = "fraction") %>%
mutate(Identity=factor(temp_Identity, levels=c(">94.5%",">98.7%","100%")))
Figure1d <- ggplot(data=d1, aes(x=database, y=fraction, fill=Identity)) +
theme_bw() +
geom_bar(color="black",stat="identity", width=0.8) +
theme(axis.text.x = element_text(angle = 45, vjust=1, hjust=1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs mapped") +
theme(axis.title.x=element_blank()) +
facet_grid(.~Relative_abundance) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10), expand=c(0,2))
FigureS2b <- ggplot(data=d2, aes(x=database, y=fraction, fill=Identity)) +
theme_bw() +
geom_bar(color="black",stat="identity", width=0.8) +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent of ASVs with relative abundance\n higher than 0.01% mapped") +
theme(axis.title.x=element_blank()) +
facet_wrap(~WWTP, ncol = 6) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10), expand=c(0,2))
ggsave(filename="output/Figure1d.pdf", plot=Figure1d, width=4.5, height=3.5, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/FigureS2b.pdf", plot=FigureS2b, width=12, height=5.3, useDingbats=FALSE, limitsize=FALSE)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Read mapping results
read_amp_classifications <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(c(1,4)) %>%
rename(ASV=V1) %>%
separate(V4, c("Kingdom","Phylum","Class","Order","Family","Genus","Species"),sep=",") %>%
mutate(Reference = (!!gsub(".*vs_(.+).sintax", "\\1", paste(input)))) %>%
arrange(readr::parse_number(ASV))
}
a <- read_amp_classifications("data/V13zotus_vs_FL-ASVs.sintax")
b <- read_amp_classifications("data/V13zotus_vs_FL-ASVs+FL-OTUs.sintax")
c <- read_amp_classifications("data/V13zotus_vs_gg_16s_13.5.sintax")
d <- read_amp_classifications("data/V13zotus_vs_rdp_16s_v16.sintax")
e <- read_amp_classifications("data/V13zotus_vs_SILVA_138_SSURef_NR99.sintax")
f <- read_amp_classifications("data/V13zotus_vs_MiDAS_2.1.sintax")
g <- read_amp_classifications("data/V13zotus_vs_Autotax_SILVA_138_SSURef_NR99.sintax")
h <- read_amp_classifications("data/V13zotus_vs_GTDB_r89.sintax")
Merged_classifications <- bind_rows(a,b,c,d,e,f,g,h)
# Read ASV table
ASVtable <- read.delim("data/V13ASVtab.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
rename(ASV=1) %>%
arrange(readr::parse_number(ASV))
# Merge ASV table and mappings
df <- left_join(ASVtable, Merged_classifications, by="ASV")
# Ranked abundance
ranked <- df %>%
gather(2:49, key="SeqID", value="counts") %>%
group_by(SeqID,Reference) %>%
arrange(desc(counts)) %>%
mutate(rank = row_number(), relative_abundance = counts/sum(counts)*100) %>%
ungroup() %>%
gather(2:8, key="Taxonomic_rank", value="Taxonomy") %>%
mutate(Reference = factor(Reference, levels = c("FL-ASVs","FL-ASVs+FL-OTUs", "gg_16s_13.5", "GTDB_r89", "MiDAS_2.1","rdp_16s_v16", "SILVA_138_SSURef_NR99","Autotax_SILVA_138_SSURef_NR99")))
Sample_metadata <- read.delim("data/Sample_metadata.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE)
ranked_w_metadata <- left_join(ranked, Sample_metadata, by="SeqID") %>%
mutate(Environment = factor(Environment, levels = c("WWTP","Anaerobic digester")))
Summary_Genus <- ranked_w_metadata %>%
filter(relative_abundance > 0.01, Taxonomic_rank==c("Genus")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary_Species <- ranked_w_metadata %>%
filter(relative_abundance > 0.01, Taxonomic_rank==c("Species")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary <- bind_rows(Summary_Genus,Summary_Species)
Summary_Mean_and_stdev <- Summary %>%
group_by(Reference, Taxonomic_rank) %>%
summarize("Mean"=mean(Classified),
"Stdev"=sd(Classified))
Summary_Genus2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.001, Taxonomic_rank==c("Genus")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary_Species2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.001, Taxonomic_rank==c("Species")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary2 <- bind_rows(Summary_Genus2,Summary_Species2)
Summary_Mean_and_stdev2 <- Summary2 %>%
group_by(Reference, Taxonomic_rank) %>%
summarize("Mean"=mean(Classified),
"Stdev"=sd(Classified))
Figure3a <- ggplot(data=Summary, aes(x=Reference, y=Classified, fill=Reference)) +
theme_bw() +
geom_violin(scale = "width") +
ylab("Percent of ASVs with relative abundance\n higher than 0.01% classified") +
scale_fill_brewer(palette="RdYlBu")+
theme(axis.title.x=element_blank()) +
facet_grid(Taxonomic_rank~Environment) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10)) +
theme(legend.position = "none") +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1))
FigureX <- ggplot(data=Summary2, aes(x=Reference, y=Classified, fill=Reference)) +
theme_bw() +
geom_violin(scale = "width") +
ylab("Percent of ASVs with relative abundance\n higher than 0.001% classified") +
scale_fill_brewer(palette="RdYlBu")+
theme(axis.title.x=element_blank()) +
facet_grid(Taxonomic_rank~Environment) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10)) +
theme(legend.position = "none") +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1))
ggsave(filename="output/Figure3a.pdf", plot=Figure3a, width=7, height=7, useDingbats=FALSE, limitsize=FALSE)
ggsave(filename="output/FigureX.pdf", plot=FigureX, width=7, height=7, useDingbats=FALSE, limitsize=FALSE)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Read mapping results
read_amp_classification <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,4) %>%
rename(ASV = V1) %>%
arrange(readr::parse_number(ASV)) %>%
mutate(ASV = str_replace_all(ASV, "[:blank:].*", "")) %>%
mutate(V4 = str_replace_all(V4, c("d:"), "")) %>%
mutate(V4 = str_replace_all(V4, c(",p:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",c:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",o:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",f:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",g:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",s:"), ",")) %>%
separate(V4,sep=",", into = c("ASV_Domain", "ASV_Phylum", "ASV_Order", "ASV_Class", "ASV_Familiy", "ASV_Genus", "ASV_Species" )) %>%
mutate(Amplicon=!!gsub("data/(.+).sintax", "\\1", paste(input))) %>%
separate(Amplicon,sep="_", into = c("Primerset", "Database"))
}
a <- read_amp_classification("data/V13_FL-ASVs.sintax")
b <- read_amp_classification("data/V13_FL-ASVs+FL-OTUs.sintax")
c <- read_amp_classification("data/V4_FL-ASVs.sintax")
d <- read_amp_classification("data/V4_FL-ASVs+FL-OTUs.sintax")
e <- read_amp_classification("data/V18_FL-ASVs.sintax")
f <- read_amp_classification("data/V18_FL-ASVs+FL-OTUs.sintax")
g <- read_amp_classification("data/V19_FL-ASVs.sintax")
h <- read_amp_classification("data/V19_FL-ASVs+FL-OTUs.sintax")
i <- read_amp_classification("data/V34_FL-ASVs.sintax")
j <- read_amp_classification("data/V34_FL-ASVs+FL-OTUs.sintax")
k <- read_amp_classification("data/V35_FL-ASVs.sintax")
l <- read_amp_classification("data/V35_FL-ASVs+FL-OTUs.sintax")
m <- read_amp_classification("data/V45_FL-ASVs.sintax")
n <- read_amp_classification("data/V45_FL-ASVs+FL-OTUs.sintax")
o <- read_amp_classification("data/V57_FL-ASVs.sintax")
p <- read_amp_classification("data/V57_FL-ASVs+FL-OTUs.sintax")
q <- read_amp_classification("data/V58_FL-ASVs.sintax")
r <- read_amp_classification("data/V58_FL-ASVs+FL-OTUs.sintax")
Merged_classifications <- bind_rows(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r)
# Read reference taxonomy
Tax_ref <- read.delim("data/tax_complete.csv",
sep = ",",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
rename(ASV=1) %>%
arrange(readr::parse_number(ASV))
# Merge ASV table and mappings
df <- left_join(Tax_ref, Merged_classifications, by="ASV") %>% replace(.,is.na(.),0) %>%
mutate(Primerset = factor(Primerset, levels = c("V13","V34","V35","V4","V45","V57","V58","V18","V19"))) %>%
mutate(Database = factor(Database, levels = c("FL-ASVs","FL-ASVs+FL-OTUs")))
Summary <- df %>%
group_by(Primerset,Database) %>%
summarize("Genus"=sum(Genus==ASV_Genus)/n()*100,
"Species"=sum(Species==ASV_Species)/n()*100) %>%
gather(3:4, key = "Taxonomic_rank", value = "Percentage")
p <- ggplot(data=Summary, aes(x=Primerset, y=Percentage, fill=Database)) +
theme_bw() +
geom_bar(color="black",stat="identity",position = position_dodge(preserve = 'single'), width=0.8) +
theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
scale_fill_brewer(palette="RdYlBu")+
ylab("Percent in silico ASVs correctly classified") +
facet_grid(.~Taxonomic_rank) +
theme(axis.title.x=element_blank()) +
scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10))
ggsave(filename="output/FigureS5b.pdf", plot=p, width=10, height=4, useDingbats=FALSE, limitsize=FALSE)
View(Summary)
library(tidyverse)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Read mapping results
read_amp_classifications <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(c(1,4)) %>%
rename(ASV=V1) %>%
separate(V4, c("Kingdom","Phylum","Class","Order","Family","Genus","Species"),sep=",") %>%
mutate(Reference = (!!gsub(".*vs_(.+).sintax", "\\1", paste(input)))) %>%
arrange(readr::parse_number(ASV))
}
a <- read_amp_classifications("data/V13zotus_vs_FL-ASVs.sintax")
b <- read_amp_classifications("data/V13zotus_vs_FL-ASVs+FL-OTUs.sintax")
c <- read_amp_classifications("data/V13zotus_vs_gg_16s_13.5.sintax")
d <- read_amp_classifications("data/V13zotus_vs_rdp_16s_v16.sintax")
e <- read_amp_classifications("data/V13zotus_vs_SILVA_138_SSURef_NR99.sintax")
f <- read_amp_classifications("data/V13zotus_vs_MiDAS_2.1.sintax")
g <- read_amp_classifications("data/V13zotus_vs_Autotax_SILVA_138_SSURef_NR99.sintax")
h <- read_amp_classifications("data/V13zotus_vs_GTDB_r89.sintax")
Merged_classifications <- bind_rows(a,b,c,d,e,f,g,h)
# Read ASV table
ASVtable <- read.delim("data/V13ASVtab.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
rename(ASV=1) %>%
arrange(readr::parse_number(ASV))
# Merge ASV table and mappings
df <- left_join(ASVtable, Merged_classifications, by="ASV")
# Ranked abundance
ranked <- df %>%
gather(2:49, key="SeqID", value="counts") %>%
group_by(SeqID,Reference) %>%
arrange(desc(counts)) %>%
mutate(rank = row_number(), relative_abundance = counts/sum(counts)*100) %>%
ungroup() %>%
gather(2:8, key="Taxonomic_rank", value="Taxonomy") %>%
mutate(Reference = factor(Reference, levels = c("FL-ASVs","FL-ASVs+FL-OTUs", "gg_16s_13.5", "GTDB_r89", "MiDAS_2.1","rdp_16s_v16", "SILVA_138_SSURef_NR99","Autotax_SILVA_138_SSURef_NR99")))
Sample_metadata <- read.delim("data/Sample_metadata.txt",
sep = "\t",
header = TRUE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE)
ranked_w_metadata <- left_join(ranked, Sample_metadata, by="SeqID") %>%
mutate(Environment = factor(Environment, levels = c("WWTP","Anaerobic digester")))
#Summarize for relative abundance >0.01%
Summary_Genus <- ranked_w_metadata %>%
filter(relative_abundance > 0.01, Taxonomic_rank==c("Genus")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary_Species <- ranked_w_metadata %>%
filter(relative_abundance > 0.01, Taxonomic_rank==c("Species")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary <- bind_rows(Summary_Genus,Summary_Species)
Summary_Mean_and_stdev <- Summary %>%
group_by(Reference, Taxonomic_rank) %>%
summarize("Mean"=mean(Classified),
"Stdev"=sd(Classified))
#Summarize for relative abundance >0.001%
Summary_Genus2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.001, Taxonomic_rank==c("Genus")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary_Species2 <- ranked_w_metadata %>%
filter(relative_abundance > 0.001, Taxonomic_rank==c("Species")) %>%
group_by(SeqID, Location, Environment, Reference, Taxonomic_rank) %>%
summarize("Classified"=100-(sum(is.na(Taxonomy))/n()*100))
Summary2 <- bind_rows(Summary_Genus2,Summary_Species2)
Summary_Mean_and_stdev2 <- Summary2 %>%
group_by(Reference, Taxonomic_rank) %>%
summarize("Mean"=mean(Classified),
"Stdev"=sd(Classified))
View(Summary_Mean_and_stdev2)
