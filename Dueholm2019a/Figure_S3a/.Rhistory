library(data.table)
library(tidyverse)
library(ggplot2)
library(stringr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
read_b6_idty <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,3) %>%
rename(ESV = V1) %>%
rename(idty = V3) %>%
mutate(idty=round(idty, digits = 0)) %>%
mutate(Dataset=!!gsub("data/(.+).b6", "\\1", paste(input)))}
read_b6_idty <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,3) %>%
rename(ESV = V1) %>%
rename(idty = V3) %>%
mutate(idty=round(idty, digits = 0)) %>%
mutate(Dataset=!!gsub("data/(.+).b6", "\\1", paste(input)))}
#True taxonomy
Test_data <- read_b6_idty("data/Test_data.b6")
Real_data <- read_b6_idty("data/Real_data.b6")
df <- rbind(Real_data, Test_data) %>%
filter(idty>=80) %>%
mutate(idty = fct_rev(as.factor(idty))
Summary()
library(data.table)
library(tidyverse)
library(ggplot2)
library(stringr)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
read_sintax_classification <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,4) %>%
rename(ESV = V1) %>%
arrange(readr::parse_number(ESV)) %>%
mutate(ESV = str_replace_all(ESV, ";tax.*$", "")) %>%
mutate(V4 = str_replace_all(V4, c("d:"), "")) %>%
mutate(V4 = str_replace_all(V4, c(",p:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",c:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",o:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",f:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",g:"), ",")) %>%
mutate(V4 = str_replace_all(V4, c(",s:"), ",")) %>%
separate(V4,sep=",", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
mutate(Method=!!gsub("data/(.+).sintax", "\\1", paste(input))) %>%
replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}
read_b6_classification <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE) %>%
select(1,2,3) %>%
rename(ESV = V1) %>%
rename(idty = V3) %>%
arrange(readr::parse_number(ESV)) %>%
mutate(ESV = str_replace_all(ESV, ";tax.*$", "")) %>%
mutate(V2 = str_replace_all(V2, "ESV.*tax=d:", "")) %>%
mutate(V2 = str_replace_all(V2, c(";"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",p:"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",c:"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",o:"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",f:"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",g:"), ",")) %>%
mutate(V2 = str_replace_all(V2, c(",s:"), ",")) %>%
separate(V2,sep=",", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
mutate(Method=!!gsub("data/(.+).b6", "\\1", paste(input))) %>%
replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}
read_qiime_classification <- function(input) {
map <- read.delim(input,
sep = "\t",
header = FALSE,
quote = "\"",
fill = TRUE,
check.names = FALSE,
stringsAsFactors = FALSE,
skip=1) %>%
select(1,2) %>%
rename(ESV = V1) %>%
arrange(readr::parse_number(ESV)) %>%
mutate(ESV = str_replace_all(ESV, "_", "")) %>%
mutate(V2 = str_replace_all(V2, "k__", "")) %>%
mutate(V2 = str_replace_all(V2, c("  p__"), "")) %>%
mutate(V2 = str_replace_all(V2, c("  c__"), "")) %>%
mutate(V2 = str_replace_all(V2, c("  o__"), "")) %>%
mutate(V2 = str_replace_all(V2, c("  f__"), "")) %>%
mutate(V2 = str_replace_all(V2, c("  g__"), "")) %>%
mutate(V2 = str_replace_all(V2, c("  s__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" p__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" c__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" o__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" f__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" g__"), "")) %>%
mutate(V2 = str_replace_all(V2, c(" s__"), "")) %>%
separate(V2,sep=";", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
mutate(Method=!!gsub("data/(.+).tsv", "\\1", paste(input))) %>%
replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}
#True taxonomy
Reference <- read_b6_classification("data/Reference.b6") %>%
rename(D_ref=D, P_ref=P, C_ref=C, O_ref=O, F_ref=F, G_ref=G, S_ref=S) %>%
select(-c(idty,Method))
#Sintax classification
Sintax80 <- read_sintax_classification("data/Sintax80.sintax")
#Sintax classification
RDP80 <- read_sintax_classification("data/RDP80.sintax")
#AutoTax classification without trimming based on percent identity
AutoTax_wo_trimming <- read_b6_classification("data/AutoTax_wo_trimming.b6")
#Usearch_tophit classification
Usearch_tophit <- read_b6_classification("data/Usearch_tophit.b6") %>%
select(-idty)
#Remove entries below identity threshold for each taxonomic rank in the Autotax_wo_trimming taxonomy
AutoTax <- AutoTax_wo_trimming
AutoTax[which(AutoTax$idty < 98.7), "S"] <- ""
AutoTax[which(AutoTax$idty < 94.5), "G"] <- ""
AutoTax[which(AutoTax$idty < 86.5), "F"] <- ""
AutoTax[which(AutoTax$idty < 82.0), "O"] <- ""
AutoTax[which(AutoTax$idty < 78.5), "C"] <- ""
AutoTax[which(AutoTax$idty < 75.0), "P"] <- ""
AutoTax <- select(AutoTax, -idty) %>%
mutate(Method="AutoTax")
#Create expected taxonomy based on Reference and percent identity with reference database
Expected <- read_b6_classification("data/Reference.b6")
Expected <- left_join(Expected, AutoTax_wo_trimming[c("ESV","idty")], by="ESV") %>%
mutate(Method="Expected") %>%
rename(idty="idty.y") %>%
select(-idty.x)
Expected[which(Expected$idty < 98.7), "S"] <- ""
Expected[which(Expected$idty < 94.5), "G"] <- ""
Expected[which(Expected$idty < 86.5), "F"] <- ""
Expected[which(Expected$idty < 82.0), "O"] <- ""
Expected[which(Expected$idty < 78.5), "C"] <- ""
Expected[which(Expected$idty < 75.0), "P"] <- ""
Expected <- select(Expected, -idty)
# Qiime2 consensus blast
q2b <- read_qiime_classification("data/q2b.tsv")
# Qiime2 sklearn
q2sk <- read_qiime_classification("data/q2sk.tsv")
# Qiime2 consensus vsearch
q2v <- read_qiime_classification("data/q2v.tsv")
All_methods <- rbind(AutoTax, Sintax80, RDP80, Usearch_tophit, q2v, q2sk,q2b)
All_methods <- left_join(All_methods, Reference, by="ESV")
Match <- All_methods %>%
mutate(Domain=if_else(D_ref=="" & D=="","Unclassified",if_else(D_ref=="" & D!="","Overclassified",if_else(D_ref!="" & D=="","Underclassified",if_else(D_ref != D,"Misclassified","Match"))))) %>%
mutate(Phylum=if_else(P_ref=="" & P=="","Unclassified",if_else(P_ref=="" & P!="","Overclassified",if_else(P_ref!="" & P=="","Underclassified",if_else(P_ref != P,"Misclassified","Match"))))) %>%
mutate(Class=if_else(C_ref=="" & C=="","Unclassified",if_else(C_ref=="" & C!="","Overclassified",if_else(C_ref!="" & C=="","Underclassified",if_else(C_ref != C,"Misclassified","Match"))))) %>%
mutate(Order=if_else(O_ref=="" & O=="","Unclassified",if_else(O_ref=="" & O!="","Overclassified",if_else(O_ref!="" & O=="","Underclassified",if_else(O_ref != O,"Misclassified","Match"))))) %>%
mutate(Family=if_else(F_ref=="" & F=="","Unclassified",if_else(F_ref=="" & F!="","Overclassified",if_else(F_ref!="" & F=="","Underclassified",if_else(F_ref != F,"Misclassified","Match"))))) %>%
mutate(Genus=if_else(G_ref=="" & G=="","Unclassified",if_else(G_ref=="" & G!="","Overclassified",if_else(G_ref!="" & G=="","Underclassified",if_else(G_ref != G,"Misclassified","Match"))))) %>%
mutate(Species=if_else(S_ref=="" & S=="","Unclassified",if_else(S_ref=="" & S!="","Overclassified",if_else(S_ref!="" & S=="","Underclassified",if_else(S_ref != S,"Misclassified","Match"))))) %>%
select("ESV","Method",17:23) %>%
gather(key="Tax_rank", value="Match",4:9)
Match_summary <- Match %>%
group_by(Method, Tax_rank) %>%
summarize("Accuracy"=sum(Match=="Match")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Overclassified")+sum(Match=="Match"))*100,
"Over-classification rate"=sum(Match=="Overclassified")/(sum(Match=="Overclassified")+sum(Match=="Unclassified"))*100,
"Under-classification rate"=sum(Match=="Underclassified")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100,
"Misclassification rate"=sum(Match=="Misclassified")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100,
"True positive rate"=sum(Match=="Match")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100) %>%
gather(key="Classification", value="Percentage",3:7)
Match_summary$Percentage[is.nan(Match_summary$Percentage)] <- 0
Match_summary <- Match_summary %>%
mutate(Tax_rank = factor(Tax_rank, levels = c("Phylum","Class","Order","Family","Genus","Species")))
View(Match)
Match1 <- Match %>%
group_by(Method, Tax_rank) %>%
summarize("Correctness"=sum(Match=="Match")/n()*100)
View(Match1)
View(Match)
View(AutoTax)
