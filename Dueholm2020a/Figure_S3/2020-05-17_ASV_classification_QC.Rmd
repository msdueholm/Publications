---
title: "AutoTax figure S3: Evaluation of AutoTax ESV classification"
author: "Morten Simonsen Dueholm"
date: "2020-05-17"
---

## R-packages
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(data.table)
library(tidyverse)
library(ggplot2)
library(stringr)
```
## Set working directory
```{r, echo=FALSE, message=FALSE, warning=FALSE}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## Define functions to import and arrange classifications
```{r, echo=FALSE, message=FALSE, warning=FALSE}
read_sintax_classification <- function(input) {
  map <- read.delim(input,
                      sep = "\t",
                      header = FALSE,
                      quote = "\"",
                      fill = TRUE,
                      check.names = FALSE,
                      stringsAsFactors = FALSE) %>%
      select(1,4) %>%
      rename(ESV = V1) %>%
      arrange(readr::parse_number(ESV)) %>%
      mutate(ESV = str_replace_all(ESV, ";tax.*$", "")) %>%
      mutate(V4 = str_replace_all(V4, c("d:"), "")) %>%
      mutate(V4 = str_replace_all(V4, c(",p:"), ",")) %>%
    mutate(V4 = str_replace_all(V4, c(",c:"), ",")) %>%
    mutate(V4 = str_replace_all(V4, c(",o:"), ",")) %>%
    mutate(V4 = str_replace_all(V4, c(",f:"), ",")) %>%
    mutate(V4 = str_replace_all(V4, c(",g:"), ",")) %>%
    mutate(V4 = str_replace_all(V4, c(",s:"), ",")) %>%
      separate(V4,sep=",", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
      mutate(Method=!!gsub("data/(.+).sintax", "\\1", paste(input))) %>%
    replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}

read_b6_classification <- function(input) {
  map <- read.delim(input,
                      sep = "\t",
                      header = FALSE,
                      quote = "\"",
                      fill = TRUE,
                      check.names = FALSE,
                      stringsAsFactors = FALSE) %>%
      select(1,2,3) %>%
      rename(ESV = V1) %>%
      rename(idty = V3) %>%
      arrange(readr::parse_number(ESV)) %>%
      mutate(ESV = str_replace_all(ESV, ";tax.*$", "")) %>%
      mutate(V2 = str_replace_all(V2, "ESV.*tax=d:", "")) %>%
      mutate(V2 = str_replace_all(V2, c(";"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",p:"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",c:"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",o:"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",f:"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",g:"), ",")) %>%
    mutate(V2 = str_replace_all(V2, c(",s:"), ",")) %>%
      separate(V2,sep=",", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
      mutate(Method=!!gsub("data/(.+).b6", "\\1", paste(input))) %>%
    replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}

read_qiime_classification <- function(input) {
  map <- read.delim(input,
                      sep = "\t",
                      header = FALSE,
                      quote = "\"",
                      fill = TRUE,
                      check.names = FALSE,
                      stringsAsFactors = FALSE,
                      skip=1) %>%
      select(1,2) %>%
      rename(ESV = V1) %>%
      arrange(readr::parse_number(ESV)) %>%
      mutate(ESV = str_replace_all(ESV, "_", "")) %>%
      mutate(V2 = str_replace_all(V2, "k__", "")) %>%
      mutate(V2 = str_replace_all(V2, c("  p__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c("  c__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c("  o__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c("  f__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c("  g__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c("  s__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" p__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" c__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" o__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" f__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" g__"), "")) %>%
    mutate(V2 = str_replace_all(V2, c(" s__"), "")) %>%
      separate(V2,sep=";", into = c("D", "P", "O", "C", "F", "G", "S" )) %>%
      mutate(Method=!!gsub("data/(.+).tsv", "\\1", paste(input))) %>%
    replace_na(list(D="",P="",C="",O="",F="",G="",S=""))}
```

## Load classifications
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#True taxonomy
Reference <- read_b6_classification("data/Reference.b6") %>%
  rename(D_ref=D, P_ref=P, C_ref=C, O_ref=O, F_ref=F, G_ref=G, S_ref=S) %>%
  select(-c(idty,Method))

#Sintax classification
Sintax80 <- read_sintax_classification("data/Sintax80.sintax")

#Sintax classification
RDP80 <- read_sintax_classification("data/RDP80.sintax")

#AutoTax classification without trimming based on percent identity 
AutoTax_wo_trimming <- read_b6_classification("data/AutoTax_wo_trimming.b6")

#Usearch_tophit classification
Usearch_tophit <- read_b6_classification("data/Usearch_tophit.b6") %>%
  select(-idty)

#Remove entries below identity threshold for each taxonomic rank in the Autotax_wo_trimming taxonomy
AutoTax <- AutoTax_wo_trimming
    AutoTax[which(AutoTax$idty < 98.7), "S"] <- ""
    AutoTax[which(AutoTax$idty < 94.5), "G"] <- ""
    AutoTax[which(AutoTax$idty < 86.5), "F"] <- ""
    AutoTax[which(AutoTax$idty < 82.0), "O"] <- ""
    AutoTax[which(AutoTax$idty < 78.5), "C"] <- ""
    AutoTax[which(AutoTax$idty < 75.0), "P"] <- ""
AutoTax <- select(AutoTax, -idty) %>%
  mutate(Method="AutoTax")

#Create expected taxonomy based on Reference and percent identity with reference database
Expected <- read_b6_classification("data/Reference.b6")
Expected <- left_join(Expected, AutoTax_wo_trimming[c("ESV","idty")], by="ESV") %>%
  mutate(Method="Expected") %>%
  rename(idty="idty.y") %>%
  select(-idty.x)
    Expected[which(Expected$idty < 98.7), "S"] <- ""
    Expected[which(Expected$idty < 94.5), "G"] <- ""
    Expected[which(Expected$idty < 86.5), "F"] <- ""
    Expected[which(Expected$idty < 82.0), "O"] <- ""
    Expected[which(Expected$idty < 78.5), "C"] <- ""
    Expected[which(Expected$idty < 75.0), "P"] <- ""
Expected <- select(Expected, -idty)

# Qiime2 consensus blast
q2b <- read_qiime_classification("data/q2b.tsv")

# Qiime2 sklearn
q2sk <- read_qiime_classification("data/q2sk.tsv")

# Qiime2 consensus vsearch
q2v <- read_qiime_classification("data/q2v.tsv")


        
All_methods <- rbind(AutoTax, Sintax80, RDP80, Usearch_tophit, q2v, q2sk,q2b)
All_methods <- left_join(All_methods, Reference, by="ESV") 
```    

## Make summaries
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
Match <- All_methods %>%
  mutate(Domain=if_else(D_ref=="" & D=="","Unclassified",if_else(D_ref=="" & D!="","Overclassified",if_else(D_ref!="" & D=="","Underclassified",if_else(D_ref != D,"Misclassified","Match"))))) %>%
  mutate(Phylum=if_else(P_ref=="" & P=="","Unclassified",if_else(P_ref=="" & P!="","Overclassified",if_else(P_ref!="" & P=="","Underclassified",if_else(P_ref != P,"Misclassified","Match"))))) %>%
  mutate(Class=if_else(C_ref=="" & C=="","Unclassified",if_else(C_ref=="" & C!="","Overclassified",if_else(C_ref!="" & C=="","Underclassified",if_else(C_ref != C,"Misclassified","Match"))))) %>%
  mutate(Order=if_else(O_ref=="" & O=="","Unclassified",if_else(O_ref=="" & O!="","Overclassified",if_else(O_ref!="" & O=="","Underclassified",if_else(O_ref != O,"Misclassified","Match"))))) %>%
  mutate(Family=if_else(F_ref=="" & F=="","Unclassified",if_else(F_ref=="" & F!="","Overclassified",if_else(F_ref!="" & F=="","Underclassified",if_else(F_ref != F,"Misclassified","Match"))))) %>%
  mutate(Genus=if_else(G_ref=="" & G=="","Unclassified",if_else(G_ref=="" & G!="","Overclassified",if_else(G_ref!="" & G=="","Underclassified",if_else(G_ref != G,"Misclassified","Match"))))) %>%
  mutate(Species=if_else(S_ref=="" & S=="","Unclassified",if_else(S_ref=="" & S!="","Overclassified",if_else(S_ref!="" & S=="","Underclassified",if_else(S_ref != S,"Misclassified","Match"))))) %>%
  select("ESV","Method",17:23) %>%
  gather(key="Tax_rank", value="Match",4:9)

Match_summary <- Match %>%
  group_by(Method, Tax_rank) %>%
  summarize("Accuracy"=sum(Match=="Match")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Overclassified")+sum(Match=="Match"))*100,
"Over-classification rate"=sum(Match=="Overclassified")/(sum(Match=="Overclassified")+sum(Match=="Unclassified"))*100,
"Under-classification rate"=sum(Match=="Underclassified")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100,
"Misclassification rate"=sum(Match=="Misclassified")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100,
"True positive rate"=sum(Match=="Match")/(sum(Match=="Underclassified")+sum(Match=="Misclassified")+sum(Match=="Match"))*100) %>%
  gather(key="Classification", value="Percentage",3:7)
Match_summary$Percentage[is.nan(Match_summary$Percentage)] <- 0

Match_summary <- Match_summary %>%
mutate(Tax_rank = factor(Tax_rank, levels = c("Phylum","Class","Order","Family","Genus","Species")))
  
```         

# Plot data
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
FigureS3b <- ggplot(data=Match_summary, aes(x=Tax_rank, y=Percentage, fill=Method)) +
  theme_bw() +
  geom_bar(color="black",stat="identity", width=0.8,position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust = 1)) +
  scale_fill_brewer(palette="RdYlBu")+
  ylab("Percentage") + 
  theme(axis.title.x=element_blank()) +
  facet_wrap(~Classification, ncol = 2) +
  scale_y_continuous(limits = c(0, 100), breaks=seq(0,100,10))
```

## Export figures
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
ggsave(filename="output/FigureS3b.pdf", plot=FigureS3b, width=12, height=8, useDingbats=FALSE, limitsize=FALSE)
```